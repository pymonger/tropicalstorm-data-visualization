{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **FA17-BL-INFO-I590-14120**\n",
    "* **Data Visualization**\n",
    "* **Gerald Manipon, MS Data Science student - Indiana University**\n",
    "* **gmanipon@iu.edu**\n",
    "* **this jupyter notebook can be found here: https://github.com/pymonger/tropicalstorm-data-visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install anaconda3 (https://www.continuum.io/downloads)\n",
    "1. Install requisite packages:\n",
    "   ```\n",
    "   conda install netCDF4\n",
    "   conda install pandoc\n",
    "   conda install -c conda-forge ipyleaflet\n",
    "   conda install -c conda-forge gdal\n",
    "   conda install -c conda-forge astropy\n",
    "   ```\n",
    "1. Add the following line to your .bash_profile and source it:\n",
    "   ```\n",
    "   export GDAL_DATA=$(gdal-config --datadir)\n",
    "   ```\n",
    "1. Download source dataset to directory containing this notebook file:\n",
    "   ```\n",
    "   wget ftp://eclipse.ncdc.noaa.gov/pub/ibtracs/v03r10/wmo/netcdf/Allstorms.ibtracs_wmo.v03r10.nc\n",
    "   ```\n",
    "1. Run jupyter:\n",
    "   ```\n",
    "   jupyter notebook\n",
    "   ```\n",
    "\n",
    "<font color='red'>**WARNING: If the above packages are not installed or the source dataset not downloaded, you will not be able to parse the NetCDF4 dataset nor will you be able to render leaflet visualizations used in this notebook.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a native of the Hawaiian Islands, Iâ€™ve lived through two hurricanes, Hurricane Iwa in 1982 and Hurricane Iniki in 1992, with a 10-year span between their occurrences. Since 1992, there have been a number of hurricanes that have come close to the islands but none that have made an impact like that of Iwa with a damage cost of \\$773 million dollars or Iniki with a damage cost of \\$3.2 billion dollars (both adjusted to 2006 dollars based on U.S. Department of Commerce Implicit Price Deflator for Construction) (Eric S. Blake, 2007). In contrast, Hurricanes Harvey and Irma ravaged the states of Texas and Florida and the US territory of Puerto Rico in one year, 2017, and it has been estimated that the economic cost of these hurricanes will exceed \\$150 billion (Horowitz, 2017). Is the occurrence of two or more costly hurricanes hitting the same US region within the same season a rare phenomenon? Or does it occur more often than not? To investigate, I will use the IBTrACKS (International Best Track Archive for Climate Stewardship) dataset to perform statistical analysis that will hopefully shed some light on these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source dataset I will use comes from the IBTrACS (International Best Track Archive for Climate Stewardship) project: https://www.ncdc.noaa.gov/ibtracs/index.php. This project is endorsed by the WMO (World Meteorological Organization) as an \"official archiving and distribution resource for tropical cyclone best track data\". The IBTrACS project provides datasets that:\n",
    "\n",
    "* Contains the most complete global set of historical tropical cyclones available\n",
    "* Combines information from numerous tropical cyclone datasets\n",
    "* Simplifies inter-agency comparisons by providing storm data from multiple sources in one place\n",
    "* Provides data in popular formats to facilitate analysis\n",
    "* Checks the quality of storm inventories, positions, pressures, and wind speeds, passing the information on to the user\n",
    "\n",
    "I will be using the IBTrACS-WMO NetCDF file that contains all storms: https://www.ncdc.noaa.gov/ibtracs/index.php?name=wmo-data. Since NetCDF is a self-describing format, info about the variables contained in this dataset can be introspected. Additional info about the variables is located here: ftp://eclipse.ncdc.noaa.gov/pub/ibtracs/v03r10/wmo/netcdf/README.netcdf.\n",
    "\n",
    "I will be performing some ETL (extraction, transformation and loading) tasks to prepare and filter (remove records with missing values) the source dataset to a tidy dataset which I will use for this analysis. The source dataset essentially aggregates every recorded tropical storm from different source agencies and provides time-series information of pertinent variables describing the storm as it progressed through its track.\n",
    "\n",
    "The variables I will include from the source dataset are:\n",
    "\n",
    "* **landfall** { True, False }\n",
    "  ```\n",
    "    short landfall(storm, time) ;\n",
    "        landfall:long_name = \"Minimum distance to land until next report (0=landfall)\" ;\n",
    "        landfall:units = \"km\" ;\n",
    "        landfall:_FillValue = -999s ;\n",
    "  ```\n",
    "  * I will aggregate this variable into a single value of **True** or **False**. **True** signifies that the storm eventually made landfall at some point in the storm's track and **False** otherwise.\n",
    "* **season** year based on season (INT)\n",
    "  ```\n",
    "    short season(storm) ;\n",
    "          season:long_name = \"Year based on season\" ;\n",
    "          season:Note = \"Following WMO,\\n\",\n",
    "                  \"NH Seasons begin 1 January and \\n\",\n",
    "                  \"SH Seasons begin 1 July the prior year\" ;\n",
    "  ```\n",
    "* **genesis_basin** { 0 = NA - North Atlantic, 1 = SA - South Atlantic, 2 = WP - West Pacific, 3 = EP - East Pacific, 4 = SP - South Pacific, 5 = NI - North Indian, 6 = SI - South Indian }\n",
    "  ```\n",
    "    byte genesis_basin(storm) ;\n",
    "        genesis_basin:long_name = \"Basin of genesis\" ;\n",
    "        genesis_basin:units = \" \" ;\n",
    "        genesis_basin:key = \"0 = NA - North Atlantic\\n\",\n",
    "    \"1 = SA - South Atlantic\\n\",\n",
    "    \"2 = WP - West Pacific\\n\",\n",
    "    \"3 = EP - East Pacific\\n\",\n",
    "    \"4 = SP - South Pacific\\n\",\n",
    "    \"5 = NI - North Indian\\n\",\n",
    "    \"6 = SI - South Indian\\n\",\n",
    "    \"7 = AS - Arabian Sea\\n\",\n",
    "    \"8 = BB - Bay of Bengal\\n\",\n",
    "    \"9 = EA - Eastern Australia\\n\",\n",
    "    \"10 = WA - Western Australia\\n\",\n",
    "    \"11 = CP - Central Pacific\\n\",\n",
    "    \"12 = CS - Carribbean Sea\\n\",\n",
    "    \"13 = GM - Gulf of Mexico\\n\",\n",
    "    \"14 = MM - Missing\" ;\n",
    "        genesis_basin:Note = \"Based on where the storm began\" ;\n",
    "  ```\n",
    "  * the additional variable info at ftp://eclipse.ncdc.noaa.gov/pub/ibtracs/v03r08/wmo/netcdf/README.netcdf states that only values 0-6 are used for this variable thus I will be discretizing the values for this variable\n",
    "* **sub_basin** of first observation { 0 = NA - North Atlantic, 1 = SA - South Atlantic, 2 = WP - West Pacific, 3 = EP - East Pacific, 4 = SP - South Pacific, 5 = NI - North Indian, 6 = SI - South Indian, 7 = AS - Arabian Sea, 8 = BB - Bay of Bengal, 9 = EA - Eastern Australia, 10 = WA - Western Australia, 11 = CP - Central Pacific, 12 = CS - Carribbean Sea, 13 = GM - Gulf of Mexico, 14 = MM - Missing }\n",
    "  ```\n",
    "    byte sub_basin(storm, time) ;\n",
    "        sub_basin:long_name = \"Sub-Basin\" ;\n",
    "        sub_basin:units = \" \" ;\n",
    "        sub_basin:key = \"0 = NA - North Atlantic\\n\",\n",
    "    \"1 = SA - South Atlantic\\n\",\n",
    "    \"2 = WP - West Pacific\\n\",\n",
    "    \"3 = EP - East Pacific\\n\",\n",
    "    \"4 = SP - South Pacific\\n\",\n",
    "    \"5 = NI - North Indian\\n\",\n",
    "    \"6 = SI - South Indian\\n\",\n",
    "    \"7 = AS - Arabian Sea\\n\",\n",
    "    \"8 = BB - Bay of Bengal\\n\",\n",
    "    \"9 = EA - Eastern Australia\\n\",\n",
    "    \"10 = WA - Western Australia\\n\",\n",
    "    \"11 = CP - Central Pacific\\n\",\n",
    "    \"12 = CS - Carribbean Sea\\n\",\n",
    "    \"13 = GM - Gulf of Mexico\\n\",\n",
    "    \"14 = MM - Missing\" ;\n",
    "        sub_basin:Note = \"Based on present location\" ;\n",
    "        sub_basin:_FillValue = '\\201' ;\n",
    "  ```\n",
    "  * this variable will remain numeric since there are 14 values\n",
    "* **time** of first observation (MJD value) (REAL)\n",
    "  ```\n",
    "    double time_wmo(storm, time) ;\n",
    "        time_wmo:long_name = \"Modified Julian Day\" ;\n",
    "        time_wmo:units = \"days since 1858-11-17 00:00:00\" ;\n",
    "        time_wmo:_FillValue = 9.969209999999999e+36 ;\n",
    "  ```\n",
    "* **lon** (longitude) of first observation (REAL)\n",
    "  ```\n",
    "    short lon_wmo(storm, time) ;\n",
    "        lon_wmo:long_name = \"Storm center longitude\" ;\n",
    "        lon_wmo:units = \"degrees_east\" ;\n",
    "        lon_wmo:scale_factor = 0.0099999998f ;\n",
    "        lon_wmo:_FillValue = -32767s ;\n",
    "  ```\n",
    "* **lat** (latitude) of first observation (REAL)\n",
    "  ```\n",
    "    short lat_wmo(storm, time) ;\n",
    "        lat_wmo:long_name = \"Storm center latitude\" ;\n",
    "        lat_wmo:units = \"degrees_north\" ;\n",
    "        lat_wmo:scale_factor = 0.0099999998f ;\n",
    "        lat_wmo:_FillValue = -32767s ;\n",
    "  ```\n",
    "* **dist2land** (distance to land) of first observation (REAL)\n",
    "  ```\n",
    "    short dist2land(storm, time) ;\n",
    "        dist2land:long_name = \"Distance to land\" ;\n",
    "        dist2land:units = \"km\" ;\n",
    "        dist2land:_FillValue = -999s ;\n",
    "  ```\n",
    "* **msw** (maximum sustained wind) of first observation (REAL)\n",
    "  ```\n",
    "    short pres_wmo(storm, time) ;\n",
    "        pres_wmo:long_name = \"Minimum Central Pressure (MCP)\" ;\n",
    "        pres_wmo:units = \"mb\" ;\n",
    "        pres_wmo:scale_factor = 0.1f ;\n",
    "        pres_wmo:_FillValue = -32767s ;\n",
    "  ```\n",
    "* **mcp** (minimum central pressure) of first observation (REAL)\n",
    "  ```\n",
    "    short wind_wmo(storm, time) ;\n",
    "        wind_wmo:long_name = \"Maximum Sustained Wind (MSW)\" ;\n",
    "        wind_wmo:units = \"kt\" ;\n",
    "        wind_wmo:scale_factor = 0.1f ;\n",
    "        wind_wmo:_FillValue = -32767s ;\n",
    "  ```\n",
    "* **nature** (storm nature) { 0 = TS - Tropical, 1 = SS - Subtropical, 2 = ET - Extratropical, 3 = DS - Disturbance, 4 = MX - Mix of conflicting reports, 5 = NR - Not Reported, 6 = MM - Missing, 7 = - Missing }\n",
    "  ```\n",
    "        nature_wmo:long_name = \"Storm nature\" ;\n",
    "        nature_wmo:key = \"0 = TS - Tropical\\n\",\n",
    "    \"1 = SS - Subtropical\\n\",\n",
    "    \"2 = ET - Extratropical\\n\",\n",
    "    \"3 = DS - Disturbance\\n\",\n",
    "    \"4 = MX - Mix of conflicting reports\\n\",\n",
    "    \"5 = NR - Not Reported\\n\",\n",
    "    \"6 = MM - Missing\\n\",\n",
    "    \"7 =  - Missing\" ;\n",
    "        nature_wmo:Note = \"Based on classification from original sources\" ;\n",
    "        nature_wmo:_FillValue = '\\201' ;\n",
    "  ```\n",
    "  * this variable will be discretized\n",
    "* **track_type** { 0 = main - cylclogenesis to cyclolysis, 1 = merge - cyclogenesis to merger, 2 = split - split to cyclolysis, 3 = other - split to merger }\n",
    "  ```\n",
    "    byte track_type(storm) ;\n",
    "        track_type:long_name = \"Track type\" ;\n",
    "        track_type:key = \"0 = main - cyclogenesis to cyclolysis\\n\",\n",
    "    \"1 = merge - cyclogenesis to merger\\n\",\n",
    "    \"2 = split - split to cyclolysis\\n\",\n",
    "    \"3 = other - split to merger\" ;\n",
    "  ```\n",
    "  * this variable will be discretized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, time\n",
    "from copy import deepcopy\n",
    "from subprocess import check_output\n",
    "import netCDF4 as NC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipyleaflet import Map, GeoJSON\n",
    "from astropy.time import Time\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "\n",
    "# get netcdf dataset\n",
    "source_file = \"Allstorms.ibtracs_wmo.v03r10.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ErfaWarning: ERFA function \"d2dtf\" yielded 1 of \"dubious year (Note 5)\" [astropy._erfa.core]\n"
     ]
    }
   ],
   "source": [
    "# define dict for discrete features\n",
    "disc_map = {\n",
    "    \"basin\": {\n",
    "         0: \"NA\", # North Atlantic\n",
    "         1: \"SA\", # South Atlantic\n",
    "         2: \"WP\", # West Pacific\n",
    "         3: \"EP\", # East Pacific\n",
    "         4: \"SP\", # South Pacific\n",
    "         5: \"NI\", # North Indian\n",
    "         6: \"SI\", # South Indian\n",
    "         7: \"AS\", # Arabian Sea\n",
    "         8: \"BB\", # Bay of Bengal\n",
    "         9: \"EA\", # Eastern Australia\n",
    "        10: \"WA\", # Western Australia\n",
    "        11: \"CP\", # Central Pacific\n",
    "        12: \"CS\", # Carribbean Sea\n",
    "        13: \"GM\", # Gulf of Mexico\n",
    "        14: \"MM\", # Missing\n",
    "    },\n",
    "    \"nature\": {\n",
    "        0: \"TS\",  # Tropical\n",
    "        1: \"SS\",  # Subtropical\n",
    "        2: \"ET\",  # Extratropical\n",
    "        3: \"DS\",  # Disturbance\n",
    "        4: \"MX\",  # Mix of conflicting reports\n",
    "        5: \"NR\",  # Not Reported\n",
    "        6: \"MM\",  # Missing\n",
    "        7: \"MM2\", # Also Missing\n",
    "    },\n",
    "    \"track_type\": {\n",
    "        0: \"main\",  # cyclogenesis to cyclolysis\n",
    "        1: \"merge\", # cyclogenesis to merger\n",
    "        2: \"split\", # split to cyclolysis\n",
    "        3: \"other\", # split to merger\n",
    "    },\n",
    "    \"month\": {\n",
    "        1: \"Jan\",\n",
    "        2: \"Feb\",\n",
    "        3: \"Mar\",\n",
    "        4: \"Apr\",\n",
    "        5: \"May\",\n",
    "        6: \"Jun\",\n",
    "        7: \"Jul\",\n",
    "        8: \"Aug\",\n",
    "        9: \"Sep\",\n",
    "       10: \"Oct\",\n",
    "       11: \"Nov\",\n",
    "       12: \"Dec\",\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# conversion factors\n",
    "kt_to_mph = 1.15078\n",
    "\n",
    "\n",
    "def get_category(mph):\n",
    "    \"\"\"Return storm category from mph value of MSW.\"\"\"\n",
    "    if mph > 155.: return 5\n",
    "    elif mph >= 131.: return 4\n",
    "    elif mph >= 111.: return 3\n",
    "    elif mph >= 96.: return 2\n",
    "    elif mph >= 74.: return 1\n",
    "    else: return 0\n",
    "    \n",
    "    \n",
    "def get_tidy_dataset(source_ds_file, tidy_ds_file):\n",
    "    \"\"\"Return tidy dataset as a data frame. Save tidy dataset\n",
    "    as an HDF5 file for re-use without having to tidy again.\"\"\"\n",
    "    \n",
    "    # open source file\n",
    "    ds = NC.Dataset(source_ds_file)\n",
    "    \n",
    "    # extract features from each hurricane and save into a list of dicts\n",
    "    data = []\n",
    "    landfall_count = 0\n",
    "    \n",
    "    # compile regular expression for matching unnamed storms\n",
    "    unnamed_re = re.compile(r'(UNNAMED|NOT NAMED)')\n",
    "    \n",
    "    for i in range(ds.dimensions['storm'].size):\n",
    "        \n",
    "        # get number of observations\n",
    "        obs = ds.variables['numObs'][i]\n",
    "        if obs <= 2: continue # skip if there are 2 or less observations\n",
    "        \n",
    "        # get storm id (storm names can be re-used so we need to track them uniquely)\n",
    "        id = np.array_str(NC.chartostring(ds.variables['storm_sn'][i,:]))[2:-1]\n",
    "        \n",
    "        # extract filterable features first\n",
    "        name = np.array_str(NC.chartostring(ds.variables['name'][i,:]))[2:-1]\n",
    "        season = ds.variables['season'][i]\n",
    "        genesis_basin = ds.variables['genesis_basin'][i]\n",
    "        \n",
    "        # extract the landfall feature: if at any time in the storm's track\n",
    "        # makes landfall, then the feature landfall == True; otherwise it\n",
    "        # will be landfall == False\n",
    "        landfall = (ds.variables['landfall'][i,:obs-1] == 0).any()\n",
    "        \n",
    "        # get max MSW (maximum sustained wind) for the storm and its category\n",
    "        wind_wmo = ds.variables['wind_wmo'][i] * kt_to_mph # convert kt to mph\n",
    "        max_msw_idx = wind_wmo.argmax()\n",
    "        max_msw = wind_wmo[max_msw_idx]\n",
    "        max_cat = get_category(max_msw)\n",
    "        \n",
    "        # get max MSW (maximum sustained wind) for the storm over land if reached landfall\n",
    "        # and its max category; determine the summary_idx which will be used to summarize\n",
    "        # the hurricane as a single data record\n",
    "        masked_msw = np.ma.masked_where(ds.variables['landfall'][i] != 0.0, wind_wmo)\n",
    "        masked_msw.set_fill_value(ds.variables['wind_wmo']._FillValue)\n",
    "        max_land_msw_idx = masked_msw.argmax()\n",
    "        if landfall:\n",
    "            max_land_msw = wind_wmo[max_land_msw_idx]\n",
    "            summary_idx = max_land_msw_idx\n",
    "        else:\n",
    "            max_land_msw = 0.0\n",
    "            summary_idx = max_msw_idx\n",
    "        max_land_cat = get_category(max_land_msw)\n",
    "            \n",
    "        # extract other filterable features\n",
    "        sub_basin = ds.variables['sub_basin'][i,:]\n",
    "        nature = ds.variables['nature_wmo'][i,:]\n",
    "        \n",
    "        # skip records that have missing values in features\n",
    "        if genesis_basin == 14:\n",
    "            continue\n",
    "        # skipping this filter; this filters out the east pacific storms\n",
    "        #if sub_basin[summary_idx] == 14:\n",
    "        #    continue\n",
    "        if nature[summary_idx] in (4, 5, 6, 7):\n",
    "            continue\n",
    "            \n",
    "        # skip records with unnamed storms\n",
    "        #if unnamed_re.search(name): continue\n",
    "        \n",
    "        # extract the rest of the features\n",
    "        time_wmo = ds.variables['time_wmo'][i,:]\n",
    "        time_iso = Time(time_wmo, format='mjd', scale='utc')\n",
    "        \n",
    "        # including the time feature as-is (absolute value) from the source doesn't make \n",
    "        # sense for prediction; a better feature to derive from the time feature is the \n",
    "        # month of year since this can give the algorithm insight into seasonal effects\n",
    "        month = time_iso[summary_idx].datetime.month\n",
    "        \n",
    "        # extract lon and handle wrapping issue\n",
    "        lon = ds.variables['lon_wmo'][i,:]\n",
    "        lon_diff = lon[0] - lon[-1]\n",
    "        if lon_diff > 180.:\n",
    "            lon[np.where(lon > 0)] -= 360.\n",
    "        elif lon_diff < 180.:\n",
    "            lon[np.where(lon < 0)] += 360.\n",
    "            \n",
    "        # extract other features\n",
    "        lat = ds.variables['lat_wmo'][i,:]\n",
    "        dist2land = ds.variables['dist2land'][i,:]\n",
    "        msw = ds.variables['wind_wmo'][i,:]\n",
    "        mcp = ds.variables['pres_wmo'][i,:]\n",
    "        tt = ds.variables['track_type'][i]\n",
    "        \n",
    "        # create GeoJSON of storm track\n",
    "        ls = { \n",
    "            \"type\": \"LineString\",\n",
    "            \"coordinates\": np.dstack((lon, lat))[0].tolist(),\n",
    "        }\n",
    "        \n",
    "        # create feature for leaflet display;\n",
    "        # stuff features into a message info for on_hover display\n",
    "        msg = \"{} {} {} {} {} {} {} {} {} {} {} {} {}\".format(i, name, obs, genesis_basin, sub_basin[summary_idx],\n",
    "                                                              time_iso[summary_idx].iso, lon[summary_idx], \n",
    "                                                              lat[summary_idx], dist2land[summary_idx],\n",
    "                                                              msw[summary_idx], mcp[summary_idx], \n",
    "                                                              nature[summary_idx], tt, landfall)\n",
    "        ls_feature = { \n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": { \"msg\": msg },\n",
    "            \"geometry\": ls,\n",
    "        }\n",
    "        \n",
    "        # create data dict\n",
    "        data.append({\n",
    "            \"id\": id,\n",
    "            \"name\": name,\n",
    "            \"genesis_basin\": disc_map['basin'][genesis_basin],\n",
    "            \"sub_basin\": disc_map['basin'][sub_basin[summary_idx]],\n",
    "            \"season\": season,\n",
    "            \"time\": time_wmo[summary_idx],\n",
    "            \"month\": disc_map['month'][month],\n",
    "            \"lon\": lon[summary_idx],\n",
    "            \"lat\": lat[summary_idx],\n",
    "            \"dist2land\": dist2land[summary_idx],\n",
    "            \"msw\": msw[summary_idx],\n",
    "            \"mcp\": mcp[summary_idx],\n",
    "            \"nature\": disc_map['nature'][nature[summary_idx]],\n",
    "            \"track_type\": disc_map['track_type'][tt],\n",
    "            \"landfall\": landfall,\n",
    "            \"feature\": json.dumps(ls_feature),\n",
    "            \"max_msw_mph\": max_msw,\n",
    "            \"max_cat\": max_cat,\n",
    "            \"max_land_msw_mph\": max_land_msw,\n",
    "            \"max_land_cat\": max_land_cat,\n",
    "        })\n",
    "        \n",
    "        # tally landfall\n",
    "        if landfall: landfall_count += 1\n",
    "        \n",
    "    # create data frame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # save data frame to HDF5\n",
    "    df.to_hdf(tidy_ds_file, \"tropicalstorms\", format=\"table\", complib=\"zlib\", complevel=9)\n",
    "    \n",
    "    # return data frame\n",
    "    return df\n",
    "\n",
    "# tidy data file\n",
    "tidy_ds_file = \"Allstorms.ibtracs_wmo.v03r10-tidy.h5\"\n",
    "\n",
    "# get tidy dataframe\n",
    "if os.path.exists(tidy_ds_file):\n",
    "    df = pd.read_hdf(tidy_ds_file)\n",
    "else:\n",
    "    df = get_tidy_dataset(source_file, tidy_ds_file)\n",
    "\n",
    "# print info\n",
    "display(Markdown(\"### landfall distribution of tiday dataset\"))\n",
    "display(Markdown(\"* total storms: {}\".format(len(data))))\n",
    "display(Markdown(\"* total storms with variable landfall == True: {}\".format(landfall_count)))\n",
    "display(Markdown(\"* total storms with variable landfall == False: {}\".format(len(data)-landfall_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
